dataset_path: lmms-lab/SEED-Bench
# dataset_path: /home/tiger/.cache/huggingface/hub/datasets--lmms-lab--SEED-Bench
# dataset_path: /home/tiger/.cache/huggingface/hub/datasets--lmms-lab--SEED-Bench/snapshots/74c4ea0cee96786739e4ccb97d227818a05ae752/data
# dataset_path: /home/tiger/.cache/huggingface/hub/datasets--lmms-lab--SEED-Bench/snapshots/74c4ea0cee96786739e4ccb97d227818a05ae752

dataset_kwargs:
  token: True
task: "seedbench_ppl"
test_split: test
output_type: multiple_choice
doc_to_visual: !function utils.seed_doc_to_visual
doc_to_text: !function utils.seed_doc_to_text_mc
doc_to_choice : !function utils.seed_doc_to_choice
doc_to_target: !function utils.seed_doc_to_mc_target
# Note that the metric name can be either a registed metric function (such as the case for GQA) or a key name returned by process_results
metric_list:
  - metric: acc
metadata:
  - version: 0.0